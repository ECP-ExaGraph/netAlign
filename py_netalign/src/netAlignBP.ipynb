{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import igraph as ig\n",
    "import networkx as nx\n",
    "import collections\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import bMatching as bm\n",
    "import importlib\n",
    "import matplotlib.pylab as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graphml(f1,f2,fl=None,input_dir=None):\n",
    "    \n",
    "    if input_dir is not None:\n",
    "        f1=input_dir+f1\n",
    "        f2=input_dir+f2\n",
    "        \n",
    "    \n",
    "    G1 = ig.read(f1,format=\"graphml\")\n",
    "    G2 = ig.read(f2,format=\"graphml\")\n",
    "    \n",
    "    L=None\n",
    "    if fl is not None:\n",
    "        if input_dir is not None:\n",
    "            fl=input_dir+fl\n",
    "        L=ig.read(fl,format=\"graphml\")\n",
    "    \n",
    "    return G1,G2,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_networks(f1,f2,fl=None,input_dir=None):\n",
    "    \n",
    "    if input_dir is not None:\n",
    "        f1=input_dir+f1\n",
    "        f2=input_dir+f2\n",
    "        \n",
    "    T=nx.read_leda(f1)\n",
    "    nx.write_graphml(T,'graph.graphml')\n",
    "    G1 = ig.read('graph.graphml',format=\"graphml\")\n",
    "    \n",
    "    T=nx.read_leda(f2)\n",
    "    nx.write_graphml(T,'graph.graphml')\n",
    "    G2 = ig.read('graph.graphml',format=\"graphml\")\n",
    "    \n",
    "    L=None\n",
    "    if fl is not None:\n",
    "        if input_dir is not None:\n",
    "            fl=input_dir+fl\n",
    "        L=ig.read(fl,format=\"graphml\")\n",
    "    \n",
    "    return G1,G2,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment(G1,G2,M):\n",
    "    \n",
    "    n1=G1.vcount()\n",
    "    n2=G2.vcount()\n",
    "    Align=[]\n",
    "    for i in range(len(M)):\n",
    "        if i < n1:\n",
    "            j=M[i][0][1]-n1\n",
    "            \n",
    "            u=G1.vs[i]['id']\n",
    "            v=G2.vs[j]['id']\n",
    "            \n",
    "            Align.append((u,v))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return Align "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_alignment(L,filename):\n",
    "    \n",
    "    fl=open(filename,\"w\")\n",
    "    for (u,v) in L:\n",
    "        t=u+\" \"+v+\"\\n\"\n",
    "        fl.write(t)\n",
    "    \n",
    "    fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_heuristic(L,perm,w):\n",
    "    \n",
    "    wk=np.concatenate((np.ravel(w),np.ravel(w)))\n",
    "    \n",
    "    for i in range(int(L.nnz/2),L.nnz):\n",
    "        wk[i]=wk[perm[i]]\n",
    "    \n",
    "    L.data=wk\n",
    "    \n",
    "    return bm.bSuitor(L,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(M1,M2,bestM):\n",
    "    \n",
    "    AL=get_alignment(G1,G2,M)\n",
    "    save_alignment(AL,res_dir+resf)\n",
    "    \n",
    "    return bestM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def othermax(L,perm,y,z):\n",
    "    \n",
    "    ##### First do the row side\n",
    "    \n",
    "    w=np.concatenate((np.ravel(z),np.ravel(z)))\n",
    "    \n",
    "    for i in range(int(L.nnz/2),L.nnz):\n",
    "        w[i]=w[perm[i]]\n",
    "    \n",
    "    L.data=w\n",
    "    \n",
    "    row,col=L.nonzero()\n",
    "    \n",
    "    omax_y=[]\n",
    "    for i in range(int(L.nnz/2)):\n",
    "        t=L.getrow(row[i]).data\n",
    "        temp=list(np.sort(t[(-t).argsort()[:2]]))\n",
    "        \n",
    "        if len(temp) == 2:\n",
    "            second =temp[0]\n",
    "            maxr=temp[1]\n",
    "        else:\n",
    "            second=0\n",
    "            maxr=temp[0]\n",
    "        \n",
    "        if second < 0:\n",
    "            second=0\n",
    "        if maxr < 0:\n",
    "            maxr=0\n",
    "        \n",
    "        if w[i]==maxr:\n",
    "            omax_y.append(second)\n",
    "        else:\n",
    "            omax_y.append(maxr)\n",
    "    \n",
    "    s=y.shape\n",
    "    omax_y=np.array(omax_y)\n",
    "    omax_y=np.matrix(omax_y.reshape(s))\n",
    "    \n",
    "    #print(z,type(z),z.shape)\n",
    "    #print(omax_y,type(omax_y))\n",
    "    #print(L)\n",
    "    \n",
    "    \n",
    "    ##### The column side\n",
    "    \n",
    "    w=np.concatenate((np.ravel(y),np.ravel(y)))\n",
    "    \n",
    "    for i in range(int(L.nnz/2),L.nnz):\n",
    "        w[i]=w[perm[i]]\n",
    "    \n",
    "    L.data=w\n",
    "    \n",
    "    row,col=L.nonzero()\n",
    "    \n",
    "    omax_z=[]\n",
    "    for i in range(int(L.nnz/2),L.nnz):\n",
    "        t=L.getrow(row[i]).data         #### Since L is symmetric we can use row here insted of col\n",
    "        temp=list(np.sort(t[(-t).argsort()[:2]]))\n",
    "        \n",
    "        if len(temp) == 2:\n",
    "            second =temp[0]\n",
    "            maxc=temp[1]\n",
    "        else:\n",
    "            second=0\n",
    "            maxc=temp[0]\n",
    "        \n",
    "        if second < 0:\n",
    "            second=0\n",
    "        if maxc < 0:\n",
    "            maxc=0\n",
    "        \n",
    "        if w[i]==maxc:\n",
    "            omax_z.append(second)\n",
    "        else:\n",
    "            omax_z.append(maxc)\n",
    "    \n",
    "    \n",
    "    s=z.shape\n",
    "    omax_z=np.array(omax_z)\n",
    "    omax_z=np.matrix(omax_z.reshape(s))\n",
    "    \n",
    "    #print(y)\n",
    "    #print(omax_z)\n",
    "    #print(L)\n",
    "    \n",
    "    \n",
    "    return omax_y,omax_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlaps_matrix(G1,G2,L=None):\n",
    "    \n",
    "    ### G1: network 1\n",
    "    ### G2: network 2\n",
    "    ### L : Bipartite graph where \n",
    "    ### left side is G1 vertices and \n",
    "    ### right side is G2 vertices\n",
    "    \n",
    "    n1=G1.vcount()\n",
    "    n2=G2.vcount()\n",
    "    \n",
    "    ### for iterating in L \n",
    "    G1_vid=list(range(n1))\n",
    "    G2_vid=list(range(n1,n1+n2))\n",
    "    \n",
    "    ###\n",
    "    nS=0\n",
    "    if L is None:  \n",
    "        ### L is not avaiable so assume complete bipartite\n",
    "        ### and assume edges are indexed accordingly\n",
    "        nS=n1*n2 \n",
    "        \n",
    "    else:\n",
    "        nS=L.ecount()\n",
    "    \n",
    "    #S=ig.Graph()  \n",
    "    #S.add_vertices(list(range(nS)))\n",
    "    edgeS=[]\n",
    "    \n",
    "    for u in G1_vid:\n",
    "        \n",
    "        nbor1=G1.neighbors(u)\n",
    "        \n",
    "        for v in G2_vid:\n",
    "            uv=-1\n",
    "            if L is not None:\n",
    "                uv=L.get_eid(u,v,directed=False,error=False)\n",
    "                \n",
    "                #if  uv == -1:\n",
    "                    #print(\"Sparse L!!\")\n",
    "                    #continue\n",
    "            else:\n",
    "                uv= u*n2+(v-n1) #### Be careful\n",
    "            \n",
    "            if uv== -1:\n",
    "                continue ## Just sanity check\n",
    "            \n",
    "            nbor2=G2.neighbors(v-n1)\n",
    "            \n",
    "\n",
    "            for i in nbor1:\n",
    "                for jj in nbor2:\n",
    "                    j=jj+n1 ### shifting the vertex id for bipartite graph\n",
    "\n",
    "                    ij=-1\n",
    "                    if L is not None:\n",
    "                        ### Now check whether the neighbors has cross edge\n",
    "                        ij=L.get_eid(i,j,directed=False,error=False)\n",
    "\n",
    "                        #if ij == -1:\n",
    "                            #print(\"L Sparse 2 !!\")\n",
    "                            #continue\n",
    "                    else:\n",
    "                        ij=(i*n2)+jj\n",
    "                    \n",
    "                    if ij==-1:\n",
    "                        continue ### Just sanity check\n",
    "\n",
    "                    \n",
    "                    edgeS.append((uv,ij))\n",
    "\n",
    "    #S.add_edges(edgeS)\n",
    "    \n",
    "    #edges = self.get_edgelist() \n",
    "    weights = [1] * len(edgeS)\n",
    "    S = sp.sparse.csr_matrix((weights, zip(*edgeS)), shape=(nS, nS))\n",
    "    S = S + sp.sparse.triu(S, 1).T + sp.sparse.tril(S, -1).T\n",
    "    S=S/2\n",
    "    \n",
    "    if L is None:\n",
    "        row=[]\n",
    "        col=[]\n",
    "        data=[1]*(n1*n2)\n",
    "        for i in range(n1):\n",
    "            for j in range(n2):\n",
    "                row.append(i)\n",
    "                col.append(j+n1)\n",
    "        row  = np.array(row)\n",
    "        col  = np.array(col)\n",
    "        data = np.array(data)\n",
    "        L = sp.sparse.coo_matrix((data, (row, col)), shape=(n1+n2, n1+n2)) \n",
    "    else:\n",
    "        edgeL=L.get_edgelist()\n",
    "        nL=L.vcount()\n",
    "        weights=[1]*len(edgeL)\n",
    "        L = sp.sparse.csr_matrix((weights, zip(*edgeL)), shape=(nL, nL))\n",
    "        L = L + sp.sparse.triu(L, 1).T + sp.sparse.tril(L, -1).T\n",
    "        L=sp.sparse.coo_matrix(L)\n",
    "\n",
    "    return S,L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netAlign(f1,f2,fl=None,resf=None,alpha=1,beta=2,gamma=0.99,maxiter=100,nbatch=20,input_dir=None,res_dir=None):\n",
    "    \n",
    "    if input_dir is None:\n",
    "        input_dir=\"/home/khan242/netAlign/data/synthetic_networks/\"\n",
    "    if res_dir is None:\n",
    "        res_dir=\"/home/khan242/netAlign/results/\"  \n",
    "     \n",
    "    if resf is None:\n",
    "        t=f1.split(\".\")\n",
    "        resf=t[0]\n",
    "    \n",
    "        t=f2.split(\".\")\n",
    "        resf=resf+\"_\"+t[0]+\".aln\"\n",
    "    \n",
    "        resp=resf.split(\".\")\n",
    "    \n",
    "    #### Output\n",
    "    bestM=[]\n",
    "    Mbase={}\n",
    "    \n",
    "    #### Reading networks\n",
    "    t1=time.perf_counter()\n",
    "    #G1,G2,L=read_graphml(f1,f2,fl,input_dir)\n",
    "    G1,G2,L=read_networks(f1,f2,fl,input_dir)\n",
    "    t2=time.perf_counter()\n",
    "    \n",
    "    print('Network Reading Done: ',round((t2-t1),2))\n",
    "    S,L=create_overlaps_matrix(G1,G2,L)\n",
    "    t3=time.perf_counter()\n",
    "    print('Computing Overlap Matrix: ',round((t3-t2),2))\n",
    "    \n",
    "    ts=time.perf_counter()\n",
    "    ###### Processing L \n",
    "    ll=int(L.nnz/2)\n",
    "    row,cols=L.nonzero()\n",
    "    perm=list(range(L.nnz))\n",
    "    \n",
    "    for i in range(ll,L.nnz):\n",
    "        c=row[i]\n",
    "        r=cols[i]\n",
    "        for j in range(ll):\n",
    "            if r==row[j] and c==cols[j]:\n",
    "                perm[i]=j\n",
    "                break\n",
    "            else:\n",
    "                perm[i]=-1 \n",
    "    \n",
    "    \n",
    "    w=np.matrix(L.data[0:ll]).T\n",
    "      \n",
    "    \n",
    "    ###### First iteration\n",
    "    \n",
    "    l3=time.perf_counter()\n",
    "    F=sp.sparse.csr_matrix(S*beta)  ### Line 3\n",
    "    \n",
    "    d=alpha*w+F.sum(1)       ### Line 4\n",
    "    l4=time.perf_counter()\n",
    "    \n",
    "    yk=np.matrix(d)          ### Line 5\n",
    "    zk=np.matrix(d)          ### Line 6\n",
    "    l5=time.perf_counter()\n",
    "    \n",
    "    Sk=sp.sparse.diags(np.ravel(yk+zk-d))*S - F ### Line 7\n",
    "    \n",
    "    \n",
    "    yk1=gamma*yk  ### Line 8\n",
    "    zk1=gamma*zk\n",
    "    Sk1=gamma*Sk\n",
    "    l6=time.perf_counter()\n",
    "    \n",
    "    Mbase[0]=round_heuristic(L,perm,yk) ### Line 10\n",
    "    Mbase[1]=round_heuristic(L,perm,zk) ### Line 11\n",
    "    \n",
    "    batch_id=2\n",
    "    te=time.perf_counter()\n",
    "    print('Iteration 1 : ',round((te-ts),2),round((l4-l3),2),round((l5-l4),2),round((l6-l5),2),round((te-l6),2))\n",
    "    for t in range(500):\n",
    "        \n",
    "        if t >= maxiter:\n",
    "            break\n",
    "        ts=time.perf_counter()\n",
    "        \n",
    "        l3=time.perf_counter()\n",
    "        tdata=list((beta*S+Sk.T).data)\n",
    "        tdata1 = [max(ele, 0) for ele in tdata] #### Lower bounding to 0\n",
    "        tdata2 = [min(ele, beta) for ele in tdata1] #### upper bounding beta\n",
    "        \n",
    "        #F=sp.sparse.csr_matrix(beta*S+Sk.T)   ### This statement is not needed since structure remains same\n",
    "        F.data=np.array(tdata2)  ### Line 3\n",
    "        \n",
    "        d=alpha*w+F.sum(1)                   ### Line 4\n",
    "        l4=time.perf_counter()\n",
    "        \n",
    "        omax_y,omax_z=othermax(L,perm,yk1,zk1)\n",
    "        yk=np.matrix(d) - omax_y                    ### Line 5\n",
    "        zk=np.matrix(d) - omax_z                    ### Line 6\n",
    "        l5=time.perf_counter()\n",
    "        \n",
    "        Sk=sp.sparse.diags(np.ravel(yk+zk-d))*S - F ### Line 7\n",
    "        \n",
    "\n",
    "        yk1=gamma*yk + (1-gamma)*yk1 ### Line 8\n",
    "        zk1=gamma*zk + (1-gamma)*zk1\n",
    "        Sk1=gamma*Sk + (1-gamma)*Sk1\n",
    "        l6=time.perf_counter()\n",
    "\n",
    "        Mbase[batch_id]=round_heuristic(L,perm,yk) ### Line 10\n",
    "        Mbase[batch_id+1]=round_heuristic(L,perm,zk) ### Line 11\n",
    "        \n",
    "        te=time.perf_counter()\n",
    "        print('Iteration',(t+2),': ',round((te-ts),2),round((l4-l3),2),round((l5-l4),2),round((l6-l5),2),round((te-l6),2))\n",
    "        \n",
    "        batch_id=batch_id+2\n",
    "        if batch_id == nbatch:\n",
    "            batch_id=0\n",
    "            #bestM=evaulate(Mbase,bestM)\n",
    "        \n",
    "    AL=get_alignment(G1,G2,Mbase[4])\n",
    "    save_alignment(AL,res_dir+resf)\n",
    "    return AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    \n",
    "    input_dir=\"/home/khan242/netAlign/data/synthetic_networks/\"\n",
    "    res_dir=\"/home/khan242/netAlign/results/\"\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast10_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast10_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast15_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast15_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast20_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast20_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast25_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast25_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dir=\"/home/khan242/netAlign/data/synthetic networks/\"\n",
    "#input_dir=\"/home/khan242/netAlign/data/real world networks/\"\n",
    "#res_dir=\"/home/khan242/netAlign/src/\"\n",
    "importlib.reload(bm)\n",
    "\n",
    "\n",
    "\n",
    "f1=\"yeast0_Y2H1.gw\"\n",
    "f2=\"yeast5_Y2H1.gw\"\n",
    "\n",
    "resf=\"yeast0_yeast5_Y2H1.aln\"    \n",
    "netAlign(f1,f2,None,resf,maxiter=6,res_dir=res_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL=netAlign('g1.graphml','g2.graphml','L.graphml',maxiter=4)\n",
    "print(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=nx.read_leda('../data/synthetic networks/yeast0_Y2H1.gw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"/home/khan242/netAlign/data/synthetic_networks/\"\n",
    "\n",
    "\n",
    "\n",
    "f1=\"yeast0_Y2H1.gw\"\n",
    "f2=\"yeast5_Y2H1.gw\"\n",
    "fl=\"L_0.05_yeast0_yeast5.graphml\"\n",
    "G1,G2,L=read_networks(f1,f2,fl,input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.get_eid(0,1769)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.es[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L.es[0],L.es[0].source,L.es[0].target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
