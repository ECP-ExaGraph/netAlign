{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import igraph as ig\n",
    "import networkx as nx\n",
    "import collections\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import bMatching as bm\n",
    "import importlib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_info(G):\n",
    "    C=G.community_multilevel()\n",
    "    G.vs[\"community\"] = C.membership\n",
    "    cinfo={}\n",
    "    for u in G.vs:\n",
    "        uid=u['id']\n",
    "        cid=u['community']\n",
    "        nbors=G.neighbors(u)\n",
    "        comms=[]\n",
    "        for v in nbors:\n",
    "            comms.append(G.vs[v]['community'])\n",
    "        \n",
    "        count=len(set(comms))\n",
    "        freq=collections.Counter(comms)\n",
    "        for keys in freq:\n",
    "            if keys is cid:\n",
    "                val=freq[keys]\n",
    "                freq[keys]=val+1\n",
    "        \n",
    "        freq_sorted=sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        cinfo[uid]=[count,cid,freq_sorted]\n",
    "    \n",
    "    return cinfo \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_networks(f1,f2):\n",
    "    \n",
    "    T=nx.read_leda(f1)\n",
    "    nx.write_graphml(T,'graph.graphml')\n",
    "    G1 = ig.read('graph.graphml',format=\"graphml\")\n",
    "    \n",
    "    T=nx.read_leda(f2)\n",
    "    nx.write_graphml(T,'graph.graphml')\n",
    "    G2 = ig.read('graph.graphml',format=\"graphml\")\n",
    "    \n",
    "    return G1,G2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_networks(G):\n",
    "    C=G.community_multilevel()\n",
    "    G.vs[\"community\"] = C.membership\n",
    "    return G,C\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_hop_neightbors(G,v,k):\n",
    "    \n",
    "    nbors=[]\n",
    "    if k is 1:\n",
    "        nbors=G.neighbors(v)\n",
    "        #nbors.append(v)\n",
    "    else:\n",
    "        prev=G.neighborhood(v,k-1)\n",
    "        cur=G.neighborhood(v,k)\n",
    "        nbors=list(set(cur)-set(prev))\n",
    "    return nbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_signature(G,C):\n",
    "    \n",
    "    com_sig={}\n",
    "    ncom=len(C)\n",
    "    sig=[0.0,0.0]\n",
    "    \n",
    "    for u in G.vs:\n",
    "        sig=[0.0,0.0]\n",
    "        nbors=G.neighbors(u)\n",
    "        deg=len(nbors)\n",
    "        cidu=u[\"community\"]\n",
    "        for v in nbors:\n",
    "            cidv=G.vs[v][\"community\"]\n",
    "            if cidu == cidv:\n",
    "                sig[0]=sig[0]+1.0\n",
    "            else:\n",
    "                sig[1]=sig[1]+1.0\n",
    "        \n",
    "        sig[0]=sig[0]/deg\n",
    "        sig[1]=sig[1]/deg\n",
    "        \n",
    "        com_sig[u[\"id\"]]=sig\n",
    "        \n",
    "    return com_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlaps_matrix(G1,G2,L,beta):\n",
    "    \n",
    "    ### G1: network 1\n",
    "    ### G2: network 2\n",
    "    ### L : Bipartite graph where \n",
    "    ### left side is G1 vertices and \n",
    "    ### right side is G2 vertices\n",
    "    \n",
    "    n1=G1.vcount()\n",
    "    n2=G2.vcount()\n",
    "    \n",
    "    ### for iterating in L \n",
    "    G1_vid=list(range(n1))\n",
    "    G2_vid=list(range(n1,n1+n2))\n",
    "    \n",
    "    ###\n",
    "    nS=0\n",
    "    if L is None:  \n",
    "        ### L is not avaiable so assume complete bipartite\n",
    "        ### and assume edges are indexed accordingly\n",
    "        nS=n1*n2 \n",
    "        \n",
    "    else:\n",
    "        nS=L.ecount()\n",
    "    \n",
    "    S=ig.Graph()  \n",
    "    S.add_vertices(list(range(nS)))\n",
    "    edgeS=[]\n",
    "    \n",
    "    for u in G1_vid:\n",
    "        \n",
    "        nbor1=G1.neighbors(u)\n",
    "        \n",
    "        for v in G2_vid:\n",
    "            uv=-1\n",
    "            if L is not None:\n",
    "                uv=L.get_eid(u,v,directed=False,error=False)\n",
    "                \n",
    "                #if  uv == -1:\n",
    "                    #print(\"Sparse L!!\")\n",
    "                    #continue\n",
    "            else:\n",
    "                uv= u*n2+(v-n1) #### Be careful\n",
    "            \n",
    "            if uv== -1:\n",
    "                continue ## Just sanity check\n",
    "            \n",
    "            nbor2=G2.neighbors(v-n1)\n",
    "            \n",
    "\n",
    "            for i in nbor1:\n",
    "                for jj in nbor2:\n",
    "                    j=jj+n1 ### shifting the vertex id for bipartite graph\n",
    "\n",
    "                    ij=-1\n",
    "                    if L is not None:\n",
    "                        ### Now check whether the neighbors has cross edge\n",
    "                        ij=L.get_eid(i,j,directed=False,error=False)\n",
    "\n",
    "                        #if ij == -1:\n",
    "                            #print(\"L Sparse 2 !!\")\n",
    "                            #continue\n",
    "                    else:\n",
    "                        ij=(i*n2)+jj\n",
    "                    \n",
    "                    if ij==-1:\n",
    "                        continue ### Just sanity check\n",
    "\n",
    "                    \n",
    "                    edgeS.append((uv,ij))\n",
    "\n",
    "    S.add_edges(edgeS)\n",
    "    print(edgeS)\n",
    "\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlaps_igraph(G1,C1,G2,C2,com_sig1,com_sig2,L,hop_coeff,alpha):\n",
    "    \n",
    "    print(\"hop: \",hop_coeff)\n",
    "    print(\"alpha: \",alpha)\n",
    "    n1=G1.vcount()\n",
    "    n2=G2.vcount()\n",
    "    hops=len(hop_coeff)\n",
    "    \n",
    "    maxdeg_factor=G1.maxdegree()+G2.maxdegree()\n",
    "    com_factor=1\n",
    "    \n",
    "    \n",
    "    ##### Bipartite graph needs unique vertex names\n",
    "    \n",
    "    B=ig.Graph()    \n",
    "    \n",
    "    G1_vid=list(range(n1))\n",
    "    G2_vid=list(range(n1,n1+n2))\n",
    "    \n",
    "    B.add_vertices(G1_vid)\n",
    "    B.add_vertices(G2_vid)\n",
    "    \n",
    "    vtype=[]\n",
    "    for i in range(B.vcount()):\n",
    "        if i < G1.vcount():\n",
    "            vtype.append(0)\n",
    "        else:\n",
    "            vtype.append(1)\n",
    "    \n",
    "    B.vs['type']=vtype  ### type denotes sides of bipartition\n",
    "    \n",
    "    if L is None:\n",
    "        edgeL=[]\n",
    "        for i in G1_vid:\n",
    "            for j in G2_vid:\n",
    "                edgeL.append((i,j))\n",
    "        B.add_edges(edgeL)\n",
    "        B.es[\"weight\"]=0\n",
    "    \n",
    "    edgeL=[]\n",
    "    \n",
    "    for u in range(n1):\n",
    "        cid1=G1.vs[u][\"community\"]\n",
    "        for v in range(n2):\n",
    "            cid2=G2.vs[v][\"community\"]\n",
    "            \n",
    "            #### check whether u,v exist in B\n",
    "            \n",
    "            uv=B.get_eid(u,v+n1,directed=False,error=False)\n",
    "            \n",
    "            if  uv == -1:\n",
    "                print(\"Sparse L!!\")\n",
    "                continue\n",
    "            \n",
    "            ### Now calculate the topological score\n",
    "            \n",
    "            val=0\n",
    "            com_factor=1\n",
    "            \n",
    "            tval=[0]*hops\n",
    "            \n",
    "            for k in range(hops):\n",
    "                \n",
    "                nbor1=get_k_hop_neightbors(G1,u,k+1)\n",
    "                nbor2=get_k_hop_neightbors(G2,v,k+1)\n",
    "                \n",
    "                com_nbor1=list((set(nbor1).intersection(set(C1[cid1]))))\n",
    "                com_nbor2=list((set(nbor2).intersection(set(C2[cid2]))))\n",
    "                \n",
    "                if k > 0:\n",
    "                    nbor1=com_nbor1\n",
    "                    nbor2=com_nbor2\n",
    "                else:\n",
    "                    t1=com_sig1[G1.vs[u][\"id\"]]\n",
    "                    t2=com_sig2[G2.vs[v][\"id\"]]\n",
    "                    com_factor=float(cosine_similarity([t1],[t2])[0])\n",
    "                \n",
    "                #print(\"nbors: \",nbor1,nbor2)\n",
    "                \n",
    "                for i in nbor1:\n",
    "                    for jj in nbor2:\n",
    "                        j=jj+n1 ### shifting the vertex id for bipartite graph\n",
    "                        \n",
    "                        ### Now check whether the neighbors has cross edge\n",
    "                        ij=B.get_eid(i,j,directed=False,error=False)\n",
    "                        \n",
    "                        if ij == -1:\n",
    "                            print(\"L Sparse 2 !!\")\n",
    "                            continue\n",
    "                                                \n",
    "                        com_i=G1.vs[i]['community']\n",
    "                        com_j=G2.vs[jj]['community']\n",
    "                        \n",
    "                        if cid1 == com_i:\n",
    "                            member1=True\n",
    "                        else:\n",
    "                            member1=False\n",
    "                    \n",
    "                        if cid2 == com_j:\n",
    "                            member2=True\n",
    "                        else:\n",
    "                            member2=False\n",
    "                        \n",
    "                        numer=1.0\n",
    "                        \n",
    "                        \n",
    "                        ###### Right now numer is always 1\n",
    "                        ###### That means, community information is irrelavant\n",
    "                        ###### We will assign appropriate value later\n",
    "                        if member1 and member2:\n",
    "                            numer=1.0\n",
    "                        else:\n",
    "                            if member1 is False and member2 is False:\n",
    "                                numer=1.0\n",
    "                            else:\n",
    "                                numer=1.0\n",
    "                        \n",
    "                                \n",
    "                        \n",
    "                        \n",
    "                        tval[k]=tval[k]+numer\n",
    "                        #print(\"before: \",u,v+n1,val,numer,denom)\n",
    "                        #val=val+((numer/denom)*hop_coeff[k])\n",
    "                        #print(\"after: \", u,v+n1,val,hop_coeff[k])\n",
    "                        \n",
    "                denom=len(nbor1)*len(nbor2)*1.0\n",
    "                tval[k]=tval[k]/denom*hop_coeff[k]\n",
    "                val=val+tval[k]\n",
    "            \n",
    "        \n",
    "            deg_diff=abs(G1.degree(u)-G2.degree(v))+1\n",
    "            deg_factor=((G1.degree(u)+G2.degree(v))/deg_diff)/maxdeg_factor\n",
    "            \n",
    "            if val> 1.01 or deg_factor > 1.01 or com_factor > 1.01:\n",
    "                print(\"Factoring problem: \",val,\", \",deg_factor,\", \",com_factor)\n",
    "            \n",
    "            node_similarity=.5*deg_factor+.5*com_factor\n",
    "            \n",
    "            B.es[uv]['weight']=alpha*val+(1.0-alpha)*node_similarity\n",
    "            \n",
    "    #for e in B.es:\n",
    "        #print(e.tuple, e['weight'])\n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlaps(G1,C1,G2,C2,com_sig1,com_sig2,L,hop_coeff,alpha):\n",
    "    \n",
    "    print(\"hop: \",hop_coeff)\n",
    "    print(\"alpha: \",alpha)\n",
    "    n1=G1.vcount()\n",
    "    n2=G2.vcount()\n",
    "    hops=len(hop_coeff)\n",
    "    \n",
    "    maxdeg_factor=G1.maxdegree()+G2.maxdegree()\n",
    "    com_factor=1\n",
    "    \n",
    "    row=[]\n",
    "    col=[]\n",
    "    data=[]\n",
    "    \n",
    "    for u in range(n1):\n",
    "        cid1=G1.vs[u][\"community\"]\n",
    "        for v in range(n2):\n",
    "            cid2=G2.vs[v][\"community\"]\n",
    "            \n",
    "            ##### TODO: NEED TO CHECK WHETHER (u,v) has edge in L\n",
    "            \n",
    "            ### Now calculate the topological score\n",
    "            \n",
    "            val=0\n",
    "            com_factor=1\n",
    "            \n",
    "            tval=[0]*hops\n",
    "            \n",
    "            for k in range(hops):\n",
    "                \n",
    "                nbor1=get_k_hop_neightbors(G1,u,k+1)\n",
    "                nbor2=get_k_hop_neightbors(G2,v,k+1)\n",
    "                \n",
    "                com_nbor1=list((set(nbor1).intersection(set(C1[cid1]))))\n",
    "                com_nbor2=list((set(nbor2).intersection(set(C2[cid2]))))\n",
    "                \n",
    "                if k > 0:\n",
    "                    nbor1=com_nbor1\n",
    "                    nbor2=com_nbor2\n",
    "                else:\n",
    "                    t1=com_sig1[G1.vs[u][\"id\"]]\n",
    "                    t2=com_sig2[G2.vs[v][\"id\"]]\n",
    "                    com_factor=float(cosine_similarity([t1],[t2])[0])\n",
    "                \n",
    "                #print(\"nbors: \",nbor1,nbor2)\n",
    "                \n",
    "                for i in nbor1:\n",
    "                    for jj in nbor2:\n",
    "                        j=jj+n1 ### shifting the vertex id for bipartite graph\n",
    "                        \n",
    "                        ### TODO: Now check whether the neighbors has cross edge\n",
    "                                                \n",
    "                        com_i=G1.vs[i]['community']\n",
    "                        com_j=G2.vs[jj]['community']\n",
    "                        \n",
    "                        if cid1 == com_i:\n",
    "                            member1=True\n",
    "                        else:\n",
    "                            member1=False\n",
    "                    \n",
    "                        if cid2 == com_j:\n",
    "                            member2=True\n",
    "                        else:\n",
    "                            member2=False\n",
    "                        \n",
    "                        numer=1.0\n",
    "                        \n",
    "                        if member1 and member2:\n",
    "                            numer=1.0\n",
    "                        else:\n",
    "                            if member1 is False and member2 is False:\n",
    "                                numer=1.0\n",
    "                            else:\n",
    "                                numer=1.0\n",
    "                        \n",
    "                                                      \n",
    "                        tval[k]=tval[k]+numer\n",
    "                        #print(\"before: \",u,v+n1,val,numer,denom)\n",
    "                        #val=val+((numer/denom)*hop_coeff[k])\n",
    "                        #print(\"after: \", u,v+n1,val,hop_coeff[k])\n",
    "                        \n",
    "                denom=len(nbor1)*len(nbor2)*1.0\n",
    "                if denom >0:\n",
    "                    tval[k]=tval[k]/denom*hop_coeff[k]\n",
    "                    val=val+tval[k]\n",
    "                  \n",
    "            deg_diff=abs(G1.degree(u)-G2.degree(v))+1\n",
    "            deg_factor=((G1.degree(u)+G2.degree(v))/deg_diff)/maxdeg_factor\n",
    "            \n",
    "            #if val> 1.01 or deg_factor > 1.01 or com_factor > 1.01:\n",
    "                #print(\"Factoring problem: \",val,\", \",deg_factor,\", \",com_factor)\n",
    "            \n",
    "            node_similarity=0.0*deg_factor+1*com_factor\n",
    "            \n",
    "            val=alpha*val+(1.0-alpha)*node_similarity\n",
    "            row.append(u)\n",
    "            col.append(v+n1)\n",
    "            data.append(val)\n",
    "            \n",
    "            ### Symmetrize\n",
    "            row.append(v+n1)\n",
    "            col.append(u)\n",
    "            data.append(val)\n",
    "            \n",
    "            \n",
    "    ### Code for scipy coo_matrix\n",
    "    \n",
    "    row  = np.array(row)\n",
    "    col  = np.array(col)\n",
    "    data = np.array(data)\n",
    "    B = sp.sparse.coo_matrix((data, (row, col)), shape=(n1+n2, n1+n2))\n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment(G1,G2,M):\n",
    "    \n",
    "    n1=G1.vcount()\n",
    "    n2=G2.vcount()\n",
    "    Align=[]\n",
    "    for i in range(len(M)):\n",
    "        if i < n1:\n",
    "            j=M[i][0][1]-n1\n",
    "            \n",
    "            u=G1.vs[i]['id']\n",
    "            v=G2.vs[j]['id']\n",
    "            \n",
    "            Align.append((u,v))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return Align \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_alignment(L,filename):\n",
    "    \n",
    "    fl=open(filename,\"w\")\n",
    "    for (u,v) in L:\n",
    "        t=u+\" \"+v+\"\\n\"\n",
    "        fl.write(t)\n",
    "    \n",
    "    fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mtx(G,u,v,m,filename):\n",
    "    \n",
    "    \n",
    "    G.write(\"temp.txt\",format=\"edgelist\")\n",
    "    \n",
    "    fl=open(filename,\"w\")\n",
    "    ft=open(\"temp.txt\",\"r\")\n",
    "    \n",
    "    header=\"%%mtx file header\"\n",
    "    fl.write(header)\n",
    "    fl.write('\\n')\n",
    "    header=str(u)+\" \"+str(v)+\" \"+str(m)\n",
    "    fl.write(header)\n",
    "    fl.write('\\n')\n",
    "    \n",
    "    for line in ft:\n",
    "        fl.write(line)\n",
    "    fl.close()\n",
    "    ft.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netAlign(f1,f2,resf=None,L=None,hop_coeff=None,alpha=0.5,input_dir=None,res_dir=None):\n",
    "    \n",
    "    if input_dir is None:\n",
    "        input_dir=\"/Users/khan242/PNNL/netAlign/data/synthetic networks/\"\n",
    "    if res_dir is None:\n",
    "        res_dir=\"/Users/khan242/PNNL/netAlign/results/\"  \n",
    "    \n",
    "    if resf is None:\n",
    "        resf=\"align.aln\"\n",
    "    \n",
    "    resp=resf.split(\".\")\n",
    "    \n",
    "        \n",
    "    #### Reading networks\n",
    "    G1,G2=read_networks(input_dir+f1,input_dir+f2)\n",
    "    \n",
    "    #### Cluster networks\n",
    "    G1,C1 =cluster_networks(G1)\n",
    "    G2,C2 =cluster_networks(G2)\n",
    "    \n",
    "    com_sig1=community_signature(G1,C1)\n",
    "    com_sig2=community_signature(G2,C2)\n",
    "    \n",
    "    if L is None or hop_coeff is \"ALL\":\n",
    "        L=create_overlaps(G1,C1,G2,C2,com_sig1,com_sig2,None,[1],alpha)\n",
    "        M=L.maximum_bipartite_matching(weights='weight')\n",
    "        AL=get_alignment(G1,G2,M)\n",
    "        save_alignment(AL,res_dir+resf)\n",
    "        \n",
    "        if hop_coeff is \"ALL\":\n",
    "            L=create_overlaps(G1,C1,G2,C2,com_sig1,com_sig2,None,[1,0.5],alpha)\n",
    "            M=L.maximum_bipartite_matching(weights='weight')\n",
    "            AL=get_alignment(G1,G2,M)\n",
    "            save_alignment(AL,res_dir+resp[0]+\"_2.\"+resp[1])\n",
    "    \n",
    "            L=create_overlaps(G1,C1,G2,C2,com_sig1,com_sig2,None,[1,0.5,0.25],alpha)\n",
    "            M=L.maximum_bipartite_matching(weights='weight')\n",
    "            AL=get_alignment(G1,G2,M)\n",
    "            save_alignment(AL,res_dir+resp[0]+\"_3.\"+resp[1])\n",
    "    else:\n",
    "        L=create_overlaps(G1,C1,G2,C2,com_sig1,com_sig2,None,hop_coeff,alpha)\n",
    "        M=bm.bSuitor(L,1)\n",
    "        AL=get_alignment(G1,G2,M)\n",
    "        save_alignment(AL,res_dir+resf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    \n",
    "    input_dir=\"/Users/khan242/PNNL/netAlign/data/synthetic networks/\"\n",
    "    res_dir=\"/Users/khan242/PNNL/netAlign/results/\"\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast10_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast10_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast15_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast15_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast20_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast20_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    \n",
    "    f1=\"yeast0_Y2H1.gw\"\n",
    "    f2=\"yeast25_Y2H1.gw\"\n",
    "    resf=\"yeast0_yeast25_Y2H1.aln\"\n",
    "    \n",
    "    netAlign(f1,f2,resf,None,\"ALL\",input_dir,res_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"/Users/khan242/PNNL/netAlign/data/synthetic networks/\"\n",
    "#input_dir=\"/Users/khan242/PNNL/netAlign/data/real world networks/\"\n",
    "res_dir=\"/Users/khan242/PNNL/netAlign/results/\"\n",
    "importlib.reload(bm)\n",
    "\n",
    "\n",
    "#f1=\"test1.gw\"\n",
    "#f2=\"test2.gw\"\n",
    "\n",
    "f1=\"yeast0_Y2H1.gw\"\n",
    "f2=\"yeast5_Y2H1.gw\"\n",
    "\n",
    "   \n",
    "\n",
    "#G1,G2=read_networks(input_dir+f1,input_dir+f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resf=\"test.aln\"\n",
    "netAlign(f1,f2,resf,[],[1],.75,input_dir,res_dir)\n",
    "!cat ../results/test.aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resf=\"yeast0_yeast5_Y2H1.aln\"    \n",
    "netAlign(f1,f2,resf,[],[1],0.95,input_dir,res_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resf=\"yeast0_yeast5_Y2H1.aln\"    \n",
    "netAlign(f1,f2,resf,[],[1],1.0,input_dir,res_dir)\n",
    "\n",
    "resf=\"yeast0_yeast5_Y2H1_2.aln\"\n",
    "netAlign(f1,f2,resf,[],[1],0.9,input_dir,res_dir)\n",
    "\n",
    "\n",
    "resf=\"yeast0_yeast5_Y2H1_3.aln\"\n",
    "netAlign(f1,f2,resf,[],[0.8,0.2],1.0,input_dir,res_dir)\n",
    "\n",
    "resf=\"yeast0_yeast5_Y2H1_4.aln\"\n",
    "netAlign(f1,f2,resf,[],[0.8,0.2],0.9,input_dir,res_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "#### Reading networks\n",
    "G1,G2=read_networks(input_dir+f1,input_dir+f2)\n",
    "    \n",
    "#### Cluster networks\n",
    "G1,C1 =cluster_networks(G1)\n",
    "G2,C2 =cluster_networks(G2)\n",
    "L=create_overlaps(G1,C1,G2,C2,None,[1])\n",
    "M=L.maximum_bipartite_matching(weights='weight')\n",
    "print(M.matching)\n",
    "AL=get_alignment(G1,G2,M)\n",
    "\n",
    "L1=create_overlaps(G1,C1,G2,C2,None,[1])\n",
    "print(L1.vcount())\n",
    "print(L1.ecount())\n",
    "print(L1.vs[0],L.vs[1])\n",
    "print(L1.es[0],L.es[1])\n",
    "M1=L1.maximum_bipartite_matching(weights='weight')\n",
    "AL1=get_alignment(G1,G2,M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reading networks\n",
    "\n",
    "cinfo1=community_info(G1)\n",
    "cinfo2=community_info(G1)\n",
    "print(cinfo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=[]\n",
    "dominant=0\n",
    "for (key,val) in cinfo1.items():\n",
    "    \n",
    "    count.append(val[0])\n",
    "    #print(val[1],val[2])\n",
    "    if val[1] == val[2][0][0]:\n",
    "        dominant=dominant+1\n",
    "    else:\n",
    "        print(key,val)\n",
    "countS=collections.Counter(count)\n",
    "print(countS,dominant/len(cinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=[]\n",
    "dominant=0\n",
    "for (key,val) in cinfo2.items():\n",
    "    \n",
    "    count.append(val[0])\n",
    "    #print(val[1],val[2])\n",
    "    if val[1] == val[2][0][0]:\n",
    "        dominant=dominant+1\n",
    "    else:\n",
    "        print(key,val)\n",
    "countS=collections.Counter(count)\n",
    "print(countS,dominant/len(cinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L.vs.attribute_names(),L.ecount(),L.vcount(),L.is_bipartite(),L.is_directed())\n",
    "save_alignment(AL,folder+\"yeast_human_Y2H2_1.aln\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=set(G1.vs['id'])\n",
    "B=set(G2.vs['id'])\n",
    "print(A.intersection(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in L.es:\n",
    "    print(i.target)\n",
    "    count=count+1\n",
    "    if count == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(G1.vcount(),G2.vcount(),L.vcount(),AL)\n",
    "\n",
    "for (u,v) in AL:\n",
    "    if u is 'MCM10' or v is 'MCM10':\n",
    "        print(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"align.aln\"\n",
    "s=t.split(\".\")\n",
    "print(s)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2,C2 =cluster_networks(G2)\n",
    "com_sig=community_signature(G2,C2)\n",
    "print(C2)\n",
    "print(com_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C2[0],len(C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(community_info(G1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=[1,0]\n",
    "t2=[.67,.33]\n",
    "print(cosine_similarity([t1],[t2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1=ig.Graph()\n",
    "G2=ig.Graph()\n",
    "L=ig.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.add_vertices([0,1,2])\n",
    "G2.add_vertices([0,1,2,3,4])\n",
    "G1.add_edges([(0,1),(0,2),(1,2)])\n",
    "G2.add_edges([(0,2),(1,2),(2,3),(2,4),(3,4)])\n",
    "\n",
    "\n",
    "L.add_vertices([0,1,2,3,4,5,6,7])\n",
    "L.add_edges([(0,5),(1,3),(1,6),(2,4),(2,7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=create_overlaps_matrix(G1,G2,None,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL=create_overlaps_matrix(G1,G2,L,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=SL.get_adjacency_sparse()\n",
    "print(type(S))\n",
    "#L=sp.sparse(S)\n",
    "ig.get_adjacency_sparse(SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
